## This file was generated by Pentaho Data Integration version 8.1.0.0-365.
#
# Here are a few examples of variables to set:
#
# PRODUCTION_SERVER = hercules
# TEST_SERVER = zeus
# DEVELOPMENT_SERVER = thor
#
# Note: lines like these with a # in front of it are comments
#
#
#Wed Oct 10 21:27:22 CEST 2018
KETTLE_CORE_JOBENTRIES_FILE=
KETTLE_LAZY_REPOSITORY=true
KETTLE_DEFAULT_DATE_FORMAT=
KETTLE_JOB_LOG_SCHEMA=
KETTLE_TRANS_PAN_JVM_EXIT_CODE=
KETTLE_CHANNEL_LOG_TABLE=
KETTLE_SPLIT_FIELDS_REMOVE_ENCLOSURE=false
vfs.sftp.userDirIsRoot=false
KETTLE_COMPATIBILITY_PUR_OLD_NAMING_MODE=N
KETTLE_CARTE_JETTY_ACCEPT_QUEUE_SIZE=
KETTLE_MAX_LOGGING_REGISTRY_SIZE=10000
KETTLE_JNDI_ROOT=
KETTLE_DEFAULT_TIMESTAMP_FORMAT=
KETTLE_MAX_LOG_TIMEOUT_IN_MINUTES=1440
KETTLE_SHARED_OBJECTS=
KETTLE_GLOBAL_LOG_VARIABLES_CLEAR_ON_EXPORT=false
KETTLE_METRICS_LOG_TABLE=
KETTLE_BATCHING_ROWSET=N
KETTLE_TRANS_LOG_TABLE=
KETTLE_JOBENTRY_LOG_SCHEMA=
KETTLE_DEFAULT_INTEGER_FORMAT=
KETTLE_METRICS_LOG_DB=
KETTLE_CARTE_JETTY_RES_MAX_IDLE_TIME=
KETTLE_PLUGIN_CLASSES=
KETTLE_FILE_OUTPUT_MAX_STREAM_LIFE=0
KETTLE_DEFAULT_BIGNUMBER_FORMAT=
KETTLE_REDIRECT_STDERR=N
KETTLE_FAIL_ON_LOGGING_ERROR=N
KETTLE_ROWSET_GET_TIMEOUT=50
KETTLE_CHANNEL_LOG_DB=
KETTLE_METRICS_LOG_SCHEMA=
KETTLE_EMPTY_STRING_DIFFERS_FROM_NULL=N
KETTLE_ROWSET_PUT_TIMEOUT=50
KETTLE_AGGREGATION_MIN_NULL_IS_VALUED=N
KETTLE_JOB_LOG_TABLE=
KETTLE_DEFAULT_NUMBER_FORMAT=
KETTLE_DEFAULT_SERVLET_ENCODING=
KETTLE_HADOOP_CLUSTER_GATEWAY_CONNECTION=false
WGET_LOG_FILE=/home/hadoop/Code/wget.log
HDFS_HOST=localhost
KETTLE_REDIRECT_STDOUT=N
KETTLE_TRANS_LOG_DB=
KETTLE_TRANS_PERFORMANCE_LOG_SCHEMA=
KETTLE_MAX_LOG_SIZE_IN_LINES=5000
KETTLE_JOBENTRY_LOG_TABLE=
KETTLE_PLUGIN_PACKAGES=
KETTLE_COMPATIBILITY_TEXT_FILE_OUTPUT_APPEND_NO_HEADER=N
KETTLE_DISABLE_CONSOLE_LOGGING=N
KETTLE_ALLOW_EMPTY_FIELD_NAMES_AND_TYPES=false
WGET_SCRIPT_PATH=/home/hadoop
KETTLE_TRANS_PERFORMANCE_LOG_DB=
KETTLE_MAX_JOB_TRACKER_SIZE=5000
PENTAHO_METASTORE_FOLDER=
KETTLE_STEP_PERFORMANCE_SNAPSHOT_LIMIT=0
KETTLE_STEP_LOG_TABLE=
KETTLE_CORE_STEPS_FILE=
KETTLE_STEP_LOG_DB=
WGET_SCRIPT_NAME=wget_file.sh
KETTLE_AGGREGATION_ALL_NULLS_ARE_ZERO=N
KETTLE_LENIENT_STRING_TO_NUMBER_CONVERSION=N
KETTLE_LOG_SIZE_LIMIT=0
KETTLE_PASSWORD_ENCODER_PLUGIN=Kettle
KETTLE_DATA_REFINERY_HTTP_CLIENT_TIMEOUT=2000
KETTLE_JOB_LOG_DB=
KETTLE_TRANS_PERFORMANCE_LOG_TABLE=
KETTLE_CHANNEL_LOG_SCHEMA=
KETTLE_STEP_LOG_SCHEMA=
KETTLE_JOBENTRY_LOG_DB=
KETTLE_CARTE_JETTY_ACCEPTORS=
KETTLE_COMPATIBILITY_MERGE_ROWS_USE_REFERENCE_STREAM_WHEN_IDENTICAL=N
KETTLE_STREAMING_TIME_LIMIT=10000
KETTLE_HIDE_DEVELOPMENT_VERSION_WARNING=N
KETTLE_LOG_TAB_REFRESH_PERIOD=1000
KETTLE_SYSTEM_HOSTNAME=
KETTLE_LOG_TAB_REFRESH_DELAY=1000
KETTLE_FILE_OUTPUT_MAX_STREAM_COUNT=1024
HDFS_PORT=9000
KETTLE_CARTE_OBJECT_TIMEOUT_MINUTES=1440
KETTLE_LOG_MARK_MAPPINGS=N
KETTLE_MAX_JOB_ENTRIES_LOGGED=5000
KETTLE_COMPATIBILITY_IMPORT_PATH_ADDITION_ON_VARIABLES=N
KETTLE_COMPATIBILITY_DB_IGNORE_TIMEZONE=N
s3.vfs.useTempFileOnUploadData=N
KETTLE_STREAMING_ROW_LIMIT=5000
KETTLE_TRANS_LOG_SCHEMA=
green_file_name=green.csv
yellow_file_name=yellow.csv
fhv_file_name=fhv.csv
NYC_HDFS_DIR=/user/hadoop/yellow_raw
NYC_IMPORT_DIR=/home/hadoop/Import